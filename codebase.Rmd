---
title: "Democracy & The Wealth of Nations"
author: "Jacob, Hugo and Jonathan"
date: "2023-02-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set working directory
knitr::opts_knit$set(root.dir = "/Users/jacoblillelund/Documents/applied-social-science/data")

library(readxl)
library(janitor)
library(tidyverse)
library(fastDummies)
library(fedmatch)#(https://cran.r-project.org/web/packages/fedmatch/vignettes/Fuzzy-matching.html)
library(broom)
library(knitr)
library(car)
library(corrplot)
library(kableExtra)
library(nortest)
library(lmtest)
library(dlookr)
```

# Load and Clean Data

## Freedom House 

Data can be downloaded at: https://freedomhouse.org/report/freedom-world
The exact dataset we used can be downloaded here: https://freedomhouse.org/sites/default/files/2023-02/All_data_FIW_2013-2023.xlsx

When running the below code, you will be prompted to select the relevant file. 

```{r warning=FALSE}
# load entire data set
freedomhouse <- read_excel(file.choose(), sheet = 2, skip = 1, col_names = TRUE) 

# clean and filter relevant data points
freedomhouse <- freedomhouse %>% 
  clean_names() %>%                                            # tidy data with janitor-package
  rename(country = country_territory, year = edition ) %>%     # rename columns
  select(c("country", "region", "c_t", "year", "pr", "cl", "total"))  # select relevant columns
```


## World Development Indicators

Data can be downloaded at https://databank.worldbank.org/source/world-development-indicators

For replication and reproducing purposes, the World Data Bank data must be downloaded in CSV format and should ideally exclude aggregates (Middle East, European Union etc.). 

When running the below code, you will be prompted to select the relevant file. 

```{r warning=FALSE}
worlddatabank <- read_csv(file.choose(), show_col_types = FALSE) %>%  
  rename_at(vars(5:ncol(.)), ~ substr(., 1, 4)) %>%   # rename year-columns appropriately
  rename("country" = "Country Name", variable = "Series Name") %>%   # rename other relevant columns
  mutate_at(vars(5:ncol(.)), as.numeric) %>%          # convert observations to numeric
  select(-c("Country Code", "Series Code"))           # exclude irrelevant column(s)
```

## Democracy Matrix Total Value Index 2020

The Democracy Matrix Ranking is compared against Freedom House to check whether the indices broadly agrees.

The data can be found here: https://www.democracymatrix.com/ranking, but cannot be downloaded as a file.
We copied it into an Google Sheet document and exported is as a CSV file. This can be found in the Github repo.

Due to the scores falling between 0-1, we scale the data by multiplying the scores with 100 to compare it to Freedom House Scores, which are scored from 0-100.

```{r warning=FALSE}
democracy_matrix <- read_csv(file.choose(), col_names = TRUE) %>% 
  clean_names() %>%                                 # tidy data with janitor-package
  select(country, total_value_index) %>%            # select columns
  mutate(total_value_index = total_value_index*100) # scale data
```

# Compare democracy-indexes
In order to compare the two downloaded democracy ranking, we merge the relevant data sets, selecting only data from The World Development Indicators for 2020, as this is the most recent results published by the Democracy Matrix Ranking project.

```{r warning=FALSE}
index_comparison <- freedomhouse %>% filter(year == 2020) %>% 
  left_join(democracy_matrix, by = "country") %>% 
  select(country, total, total_value_index) %>%  # select relevant columns
  filter(!is.na(total_value_index)) # filter for rows with missing values (territories are not included in Democracy Matrix ranking)

# Draw Scatterplot
index_comparison %>% 
  ggplot(aes(x = total, y = total_value_index, label = country)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  xlab("Freedom House Score") +
  ylab("Democracy Matrix Ranking Score") +
  ggtitle("Comparing Democracy Scores Country-by-country") +
  theme_minimal()

# Check correlation
cor(index_comparison$total, index_comparison$total_value_index)

```

We can see that the Freedom House democracy index has a very high correlation with the democracy matrix ranking project. 

# Inspect missing data

## Define generalizable

The below function is written such that when run on a data set downloaded from The World Data Bank World Development Indicators it will provide an overview of how much data is missing along with visualisations.

```{r}

missing_data_function <- function(data_file) {
  
  col_names <- colnames(data_file)

  years <- col_names[3:length(col_names)]

  variables <- unique(na.omit(data_file[,2]))

  missing_data <- data.frame(variable = variables)

  for (v in missing_data$variable) {
    for (year in years) {
  
      n_na <- data_file %>%
        filter(variable == v) %>% 
        select(year) %>% 
        summarize(num_na = sum(is.na(.)))
      
      n_total <- data_file %>%
        filter(variable == v) %>% 
        select(year) %>% 
        nrow()

      md <- as.numeric(n_na/n_total)

      missing_data[missing_data$variable == v, year] <- md
    }
  }

  row_means <- rowMeans(missing_data[1:nrow(missing_data),2:ncol(missing_data)], na.rm = TRUE)
  col_means <- colMeans(missing_data[1:nrow(missing_data),2:ncol(missing_data)], na.rm = TRUE)

  missing_data <- rbind(missing_data, c("mean col", col_means))
  missing_data$mean_row <- c(row_means, NA)
  
  df_col_means <- data.frame(years, col_means)

  col_means_plot <- ggplot(df_col_means, aes(x = years, y = col_means, fill = years)) +
                    geom_bar(stat = "identity") +
                    labs(x = "Year", y = "Missing Data", title = "Missing Data By Year")
  

  df_row_means <- data.frame("variable" = missing_data[1:(nrow(missing_data)-1), 1], 
                             "row_means" = missing_data[1:(nrow(missing_data)-1), ncol(missing_data)])

  row_means_plot <- ggplot(df_row_means, aes(x = variable, y = row_means, fill = variable)) +
                    geom_bar(stat = "identity") +
                    labs(x = "Variable", y = "Missing Data (Decimal)", title = "Missing Data By Variable") +
                    theme(axis.text.x = element_text(angle = 90, size = 8, hjust = 1))

list(missing_data, col_means_plot, row_means_plot)
}

```

## Inspecting our data

```{r warning=FALSE}
missing_data_function(worlddatabank)
```

# Modelling
Based on the missing data for the macroeconomic variables, we have decided to model based on year 2020 and excluded the Gini-coefficient due to missing roughly 3/4 data points. Furthermore, our research shows us that there a different standards for reporting Gini between countries.

## Subset world data bank data to only include 2020 data for all countries excluding the Gini-variable
```{r}
worlddatabank_2020 <- worlddatabank %>%
  select(country, variable, '2020') %>% 
  filter(variable != "Gini index") 

# Convert into wide-format for later modelling and exploration of data 
worlddatabank_2020 <-  worlddatabank_2020 %>%
  pivot_wider(names_from = variable, values_from = "2020", id_cols = "country") %>% 
  clean_names() %>%  # clean column names 
  slice(1:(which(country == "Zimbabwe")))     # Include rows up to and including Zimbabwe (in case aggregate scores have been downloaded)
```

## Filter freedomhouse-data for 2020 only
```{r}
freedomhouse_2020 <- freedomhouse %>%
  filter(year == 2020)
```

# Merging  final World Data Bank dataset with the freedom house dataset
Merging the dataset worlddatabank_2020 and freedomhouse_2020 creates issues, as the same naming conventions have not been followed on different countries. For instance, "Turkiye" from the world data bank is equivalent to the "Turkey"-entry in the freedomhouse dataset.

This is solved used the fedmatch package, that allows "fuzzy" merging. An alternative option is using dirty_cat in Python. 

## Merge our final World Data Bank dataset with the freedomhouse dataset
We still have the dataset freedomhouse_2020 which we can merge with our data for all countries

Merging as in the previous example using fedmatch::merge_plus

```{r}
# Add unique key for each observation to both datasets for fedmatch::merge_plus (function requirement)
worlddatabank_2020$unique_key_1 <- 1:nrow(worlddatabank_2020)
freedomhouse_2020$unique_key_2 <- 1:nrow(freedomhouse_2020)

# Merge datasets using merge_plus and the Weighted Jacquard algorithm -
  # NB: Order of data sets matter
fuzzy_result <- merge_plus(data1 = worlddatabank_2020, 
                          data2 = freedomhouse_2020,
                          by.x = "country",
                          by.y = "country", match_type = "fuzzy", 
                          fuzzy_settings = build_fuzzy_settings(method = "jw", maxDist = .2),
                          unique_key_1 = "unique_key_1",
                          unique_key_2 = "unique_key_2") 

# Check if any rows did not get a match
print(fuzzy_result$data1_nomatch)

```

22 rows did not have a match. These have been manually inspected, and only 6 of these are suppossed to be matched with a corresponding row in the freedomhouse data-set, namely:

1. "South Korea", "Korea, Rep."
2. "Samoa", "American Samoa"
3. "Congo (Kinshasa)", "Congo, Dem. Rep."
4. "Congo (Brazzaville)", "Congo, Rep."
5. "The Gambia", "Gambia, The"
6. "North Korea", "Korea, Dem. People's Rep."

The entries are manually renamed:

```{r}
freedomhouse_2020 <- freedomhouse_2020 %>%
  mutate(country = case_when(
    country == "South Korea" ~ "Korea, Rep.",
    country == "Samoa" ~ "American Samoa",
    country == "Congo (Kinshasa)" ~ "Congo, Dem. Rep.",
    country == "Congo (Brazzaville)" ~ "Congo, Rep.",
    country == "The Gambia" ~ "Gambia, The",
    country == "North Korea" ~ "Korea, Dem. People's Rep.",
    TRUE ~ country))
```

We can then rerun the script and inspect again:

```{r}

fuzzy_result<- merge_plus(data1 = worlddatabank_2020, 
                          data2 = freedomhouse_2020,
                          by.x = "country",
                          by.y = "country", match_type = "fuzzy", 
                          fuzzy_settings = build_fuzzy_settings(method = "jw", maxDist = .2),
                          unique_key_1 = "unique_key_1",
                          unique_key_2 = "unique_key_2") 

# Check the rows that did not get an exact match
print(fuzzy_result$data1_nomatch)
```

We do not expect these remaining 16 rows to be matched, as the freedom house data set does not contain democracy scores for these entities.

```{r}
# Inspect non-exact matches
fuzzy_result$matches %>%
  filter(country_1 != country_2) %>%
  select(country_1, country_2)
```

Of the non-exact matches, a couple of them are wrongly matched:

1. Greenland is matched with	Grenada
2. Guam	is matched with Guatemala
3. New Caledonia is matched with	New Zealand
4. Northern Mariana Islands is matched with	Northern Cyprus

These four entities are not rated by Freedom House, so we do not expect any matches, and can exclude the rows and save the remaining matches to a data frame.

```{r}
# Save matches to data frame and exclude the relevant rows
modelling_data <- as.data.frame(fuzzy_result$matches) %>% 
  filter(!(country_1 %in% c("Greenland", "Guam", "New Caledonia", "Northern Mariana Islands")))
```


```{r}
# Rearrange columns:

modelling_data <- modelling_data %>%
  select(-c(unique_key_2, unique_key_1, country_2, region, c_t, tier, year, pr, cl)) %>% # exclude irrelevant columns
  rename(democracy_score = total, country = country_1)  %>%                              # rename relevant columns
  select(country, everything())                                                          # rearrange

```

# Exploring the data

## Extracting numerical summary of variables
```{r}
# diagnoses numerical variables and extract summary stats
diagnose_numeric(modelling_data) %>% flextable()
```

## Histogram of Democracy Score distribution

```{r}
ggplot(modelling_data, aes(x = democracy_score)) + # map the democracy score variable
  geom_histogram(fill = "steelblue") +  # create histogram with fill color
  geom_vline(aes(xintercept = mean(democracy_score)), linetype = 2) + #creating dashed line at x=0
  theme_minimal() + 
  ylab("Percent-points") + 
  xlab("Democracy Score")
```

## Create scatterplots of all variables against democracy score

```{r}
# Convert data to long format 
modelling_data_long <- modelling_data %>%
  pivot_longer(cols = !c(country, democracy_score),
               names_to = "variable",
               values_to = "value")

# Plot the data
modelling_data_long %>% 
  ggplot(aes(x = value, y = democracy_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  theme_minimal() +
  facet_wrap(~variable, scales = "free_x") +
  scale_x_continuous(limits = function(x) {             # leave out 5% of max values for each variable for better overview
    q <- quantile(x, c(0.0, 0.95))
    c(min(q), max(q))
  }, expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 100))
```

## Inspecting predictor variables one by one
The below code is useful for an easier manual inspection of each variables distribution and association to the democracy


### GDP growth

#### Histogram
```{r}
ggplot(modelling_data, aes(x = gdp_growth_annual_percent)) + 
  geom_histogram(fill = "steelblue") +  
  geom_vline(aes(xintercept = mean(gdp_growth_annual_percent)), linetype = 2) + 
  theme_minimal() + 
  ylab("Number of countries")
```
#### Scatterplot

```{r}
ggplot(modelling_data, aes(x = gdp_growth_annual_percent, y = democracy_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(x = "GDP growth (annual %)", y = "Total") +
  ggtitle("Democracy Score vs. GDP growth") +
  theme_minimal()
```

### GDP pr capita

#### Histogram
```{r}
ggplot(modelling_data, aes(x = gdp_per_capita_constant_2015_us)) + 
  geom_histogram(fill = "steelblue") +  
  geom_vline(aes(xintercept = mean(gdp_per_capita_constant_2015_us)), linetype = 2) + 
  theme_minimal() + 
  ylab("Number of countries")
```
#### Scatterplot

```{r}
ggplot(modelling_data, aes(x = gdp_per_capita_constant_2015_us, y = democracy_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(x = "GDP per capita (constant 2015 US$)", y = "Total") +
  ggtitle("Democracy Score vs. GDP per capita") +
  theme_minimal()
```

### Tax Revenue

#### Histogram
```{r}
ggplot(modelling_data, aes(x = tax_revenue_percent_of_gdp)) + 
  geom_histogram(fill = "steelblue") +  
  geom_vline(aes(xintercept = mean(tax_revenue_percent_of_gdp)), linetype = 2) + 
  theme_minimal() + 
  ylab("Number of countries")
```
#### Scatterplot

```{r}
ggplot(modelling_data, aes(x = tax_revenue_percent_of_gdp, y = democracy_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(x = "Tax revenue (% of GDP)", y = "Total") +
  ggtitle("Democracy Score vs. Tax revenue") +
  theme_minimal()
```

### Natural resources

#### Histogram 
```{r}
ggplot(modelling_data, aes(x = total_natural_resources_rents_percent_of_gdp)) + 
  geom_histogram(fill = "steelblue") +  
  geom_vline(aes(xintercept = mean(total_natural_resources_rents_percent_of_gdp)), linetype = 2) +
  theme_minimal() + 
  ylab("Number of countries")
```
#### Scatterplot
```{r}
ggplot(modelling_data, aes(x = total_natural_resources_rents_percent_of_gdp, y = democracy_score)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(x = "Total natural resources rents (% of GDP)", y = "Total") +
  ggtitle("Democracy Score vs. Natural resources rents") +
  theme_minimal()
```

# Modelling
Based on the missing data for the macroeconomic variables, we have decided to model based on year 2020 and for the four variables for which we have more than 50% of the data available.

For our  multiple regression model we aim to model based on data for one given year, and not time-series data. For 2020 and 2021, this intuitively seems to be a result of the COVID-19 pandemic, and for 2022 simply just, that the data was not released by the time we gathered data (beginning of 2023). We suggest that the rather incomplete data for the years under COVID-19 are not representative of the macro-economy in a normal year. 

Despite having more complete data in years preceeding 2020, we do still believe it makes more sense to model on data from the most recent representative year. Given the above reasons, we suggest 2020 to be the most relevant year to model on.

As we are missing 74% for the Gini-variable, we have decided to exclude this in our model. 


## Creating model(s)

As the scales of measurement differs greatly between the variables, we normalize them all to be able to compare their coefficients:

```{r}
# Select the predictor variables to be normalized
predictor_vars <- modelling_data %>%
  select(-democracy_score, -country) %>%
  colnames()

# Normalize the predictor variables and save to a new data frame
modelling_data_norm <- modelling_data
modelling_data_norm[predictor_vars] <- scale(modelling_data_norm[predictor_vars])
```

Each value in the variable-columns now represent how many standard deviations the given country falls from the mean in regards to that variable.

We can then fit the linear regression model
```{r}
# Fit the linear regression model with the normalized predictor variables
democracy_score_model_norm <- stan_glm(democracy_score ~ 
                                  gdp_growth_annual_percent + 
                                  gdp_per_capita_constant_2015_us  +
                                  tax_revenue_percent_of_gdp +
                                  total_natural_resources_rents_percent_of_gdp,
                                data = modelling_data_norm, refresh = 0)

summary(democracy_score_model_norm)

```


# Checking assumptions
Check assumptions such as linearity, normality, and homoscedasticity to ensure that the model is appropriate for the data.

```{r}
check_model(democracy_score_model_norm)
```